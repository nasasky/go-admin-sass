package app_service

import (
	"context"
	"database/sql"
	"fmt"
	"log"
	"runtime"
	"sync"
	"time"

	"gorm.io/gorm"
)

// DatabasePoolManager æ•°æ®åº“è¿æ¥æ± ç®¡ç†å™¨
type DatabasePoolManager struct {
	db                *gorm.DB
	sqlDB             *sql.DB
	config            *DatabasePoolConfig
	healthCheckTicker *time.Ticker
	ctx               context.Context
	cancel            context.CancelFunc
	mu                sync.RWMutex
	lastHealthCheck   time.Time
	isHealthy         bool
}

// DatabasePoolConfig æ•°æ®åº“è¿æ¥æ± é…ç½®
type DatabasePoolConfig struct {
	MaxOpenConns        int           `json:"max_open_conns"`        // æœ€å¤§æ‰“å¼€è¿æ¥æ•°
	MaxIdleConns        int           `json:"max_idle_conns"`        // æœ€å¤§ç©ºé—²è¿æ¥æ•°
	ConnMaxLifetime     time.Duration `json:"conn_max_lifetime"`     // è¿æ¥æœ€å¤§ç”Ÿå­˜æ—¶é—´
	ConnMaxIdleTime     time.Duration `json:"conn_max_idle_time"`    // è¿æ¥æœ€å¤§ç©ºé—²æ—¶é—´
	HealthCheckInterval time.Duration `json:"health_check_interval"` // å¥åº·æ£€æŸ¥é—´éš”
	SlowQueryThreshold  time.Duration `json:"slow_query_threshold"`  // æ…¢æŸ¥è¯¢é˜ˆå€¼
}

// GetOptimalDatabasePoolConfig è·å–æœ€ä¼˜æ•°æ®åº“è¿æ¥æ± é…ç½®
func GetOptimalDatabasePoolConfig() *DatabasePoolConfig {
	// åŸºäºCPUæ ¸å¿ƒæ•°åŠ¨æ€è®¡ç®—è¿æ¥æ± å¤§å°
	cpuCount := runtime.NumCPU()

	config := &DatabasePoolConfig{
		MaxOpenConns:        cpuCount * 4,           // CPUæ ¸å¿ƒæ•°çš„4å€
		MaxIdleConns:        cpuCount * 2,           // CPUæ ¸å¿ƒæ•°çš„2å€
		ConnMaxLifetime:     time.Hour,              // è¿æ¥æœ€é•¿å­˜æ´»1å°æ—¶
		ConnMaxIdleTime:     10 * time.Minute,       // ç©ºé—²è¿æ¥10åˆ†é’Ÿåå›æ”¶
		HealthCheckInterval: 30 * time.Second,       // æ¯30ç§’å¥åº·æ£€æŸ¥
		SlowQueryThreshold:  500 * time.Millisecond, // æ…¢æŸ¥è¯¢é˜ˆå€¼500ms
	}

	log.Printf("æ•°æ®åº“è¿æ¥æ± é…ç½® - MaxOpenConns: %d, MaxIdleConns: %d, CPUæ ¸å¿ƒæ•°: %d",
		config.MaxOpenConns, config.MaxIdleConns, cpuCount)

	return config
}

// NewDatabasePoolManager åˆ›å»ºæ•°æ®åº“è¿æ¥æ± ç®¡ç†å™¨
func NewDatabasePoolManager(db *gorm.DB, config *DatabasePoolConfig) (*DatabasePoolManager, error) {
	if db == nil {
		return nil, fmt.Errorf("æ•°æ®åº“è¿æ¥ä¸ºç©ºï¼Œæ— æ³•åˆ›å»ºè¿æ¥æ± ç®¡ç†å™¨")
	}

	if config == nil {
		config = GetOptimalDatabasePoolConfig()
	}

	sqlDB, err := db.DB()
	if err != nil {
		return nil, fmt.Errorf("è·å–SQL DBå¤±è´¥: %w", err)
	}

	// åº”ç”¨è¿æ¥æ± é…ç½®
	sqlDB.SetMaxOpenConns(config.MaxOpenConns)
	sqlDB.SetMaxIdleConns(config.MaxIdleConns)
	sqlDB.SetConnMaxLifetime(config.ConnMaxLifetime)
	sqlDB.SetConnMaxIdleTime(config.ConnMaxIdleTime)

	ctx, cancel := context.WithCancel(context.Background())

	manager := &DatabasePoolManager{
		db:                db,
		sqlDB:             sqlDB,
		config:            config,
		ctx:               ctx,
		cancel:            cancel,
		healthCheckTicker: time.NewTicker(config.HealthCheckInterval),
		lastHealthCheck:   time.Now(),
		isHealthy:         true,
	}

	// å¯åŠ¨å¥åº·æ£€æŸ¥
	manager.startHealthCheck()

	log.Printf("æ•°æ®åº“è¿æ¥æ± ç®¡ç†å™¨å·²åˆå§‹åŒ–")
	return manager, nil
}

// startHealthCheck å¯åŠ¨å¥åº·æ£€æŸ¥
func (dpm *DatabasePoolManager) startHealthCheck() {
	go func() {
		defer func() {
			if r := recover(); r != nil {
				log.Printf("æ•°æ®åº“å¥åº·æ£€æŸ¥å™¨å‘ç”Ÿpanic: %v", r)
				// é‡å¯å¥åº·æ£€æŸ¥
				time.Sleep(5 * time.Second)
				dpm.startHealthCheck()
			}
		}()

		log.Printf("æ•°æ®åº“å¥åº·æ£€æŸ¥å™¨å·²å¯åŠ¨")

		for {
			select {
			case <-dpm.ctx.Done():
				log.Printf("æ•°æ®åº“å¥åº·æ£€æŸ¥å™¨å·²åœæ­¢")
				return
			case <-dpm.healthCheckTicker.C:
				dpm.performHealthCheck()
			}
		}
	}()
}

// performHealthCheck æ‰§è¡Œå¥åº·æ£€æŸ¥
func (dpm *DatabasePoolManager) performHealthCheck() {
	dpm.mu.Lock()
	defer dpm.mu.Unlock()

	start := time.Now()

	// æ‰§è¡Œç®€å•æŸ¥è¯¢æµ‹è¯•è¿æ¥
	ctx, cancel := context.WithTimeout(context.Background(), 5*time.Second)
	defer cancel()

	err := dpm.sqlDB.PingContext(ctx)
	duration := time.Since(start)

	dpm.lastHealthCheck = time.Now()

	if err != nil {
		dpm.isHealthy = false
		log.Printf("âŒ æ•°æ®åº“å¥åº·æ£€æŸ¥å¤±è´¥: %v, è€—æ—¶: %v", err, duration)
		orderMetrics.RecordError("database")
	} else {
		dpm.isHealthy = true
		if duration > dpm.config.SlowQueryThreshold {
			log.Printf("âš ï¸  æ•°æ®åº“å¥åº·æ£€æŸ¥å“åº”è¾ƒæ…¢: %v", duration)
		}
	}

	// è®°å½•è¿æ¥æ± ç»Ÿè®¡ä¿¡æ¯
	stats := dpm.sqlDB.Stats()

	log.Printf("æ•°æ®åº“è¿æ¥æ± çŠ¶æ€ - æ‰“å¼€è¿æ¥: %d/%d, ä½¿ç”¨ä¸­: %d, ç©ºé—²: %d, ç­‰å¾…: %d, å¥åº·: %v",
		stats.OpenConnections, dpm.config.MaxOpenConns,
		stats.InUse, stats.Idle, stats.WaitCount, dpm.isHealthy)

	// æ£€æŸ¥è¿æ¥æ± å¼‚å¸¸æƒ…å†µ
	dpm.checkPoolAlerts(stats)
}

// checkPoolAlerts æ£€æŸ¥è¿æ¥æ± æŠ¥è­¦æ¡ä»¶
func (dpm *DatabasePoolManager) checkPoolAlerts(stats sql.DBStats) {
	// è¿æ¥æ•°æ¥è¿‘ä¸Šé™æŠ¥è­¦
	utilizationRate := float64(stats.OpenConnections) / float64(dpm.config.MaxOpenConns)
	if utilizationRate > 0.8 {
		log.Printf("âš ï¸  è­¦å‘Š: æ•°æ®åº“è¿æ¥æ± ä½¿ç”¨ç‡è¿‡é«˜ %.1f%% (%d/%d)",
			utilizationRate*100, stats.OpenConnections, dpm.config.MaxOpenConns)
	}

	// ç­‰å¾…è¿æ¥è¿‡å¤šæŠ¥è­¦
	if stats.WaitCount > 10 {
		log.Printf("âš ï¸  è­¦å‘Š: æ•°æ®åº“è¿æ¥æ± ç­‰å¾…é˜Ÿåˆ—è¿‡é•¿ %d", stats.WaitCount)
	}

	// è¿æ¥è¶…æ—¶æŠ¥è­¦
	if stats.WaitDuration > time.Second {
		log.Printf("âš ï¸  è­¦å‘Š: æ•°æ®åº“è¿æ¥ç­‰å¾…æ—¶é—´è¿‡é•¿ %v", stats.WaitDuration)
	}
}

// GetHealthStatus è·å–å¥åº·çŠ¶æ€
func (dpm *DatabasePoolManager) GetHealthStatus() map[string]interface{} {
	dpm.mu.RLock()
	defer dpm.mu.RUnlock()

	stats := dpm.sqlDB.Stats()

	return map[string]interface{}{
		"healthy":             dpm.isHealthy,
		"last_check":          dpm.lastHealthCheck,
		"open_connections":    stats.OpenConnections,
		"max_open_conns":      dpm.config.MaxOpenConns,
		"in_use":              stats.InUse,
		"idle":                stats.Idle,
		"wait_count":          stats.WaitCount,
		"wait_duration_ms":    stats.WaitDuration.Milliseconds(),
		"max_idle_closed":     stats.MaxIdleClosed,
		"max_lifetime_closed": stats.MaxLifetimeClosed,
	}
}

// ExecuteWithRetry å¸¦é‡è¯•çš„æ•°æ®åº“æ‰§è¡Œ
func (dpm *DatabasePoolManager) ExecuteWithRetry(operation func(*gorm.DB) error, maxRetries int) error {
	var lastErr error

	for i := 0; i <= maxRetries; i++ {
		// æ£€æŸ¥å¥åº·çŠ¶æ€
		if !dpm.IsHealthy() && i == 0 {
			log.Printf("æ•°æ®åº“ä¸å¥åº·ï¼Œå°è¯•ç­‰å¾…æ¢å¤...")
			time.Sleep(time.Second)
		}

		err := operation(dpm.db)
		if err == nil {
			return nil
		}

		lastErr = err

		// æ£€æŸ¥æ˜¯å¦ä¸ºå¯é‡è¯•çš„é”™è¯¯
		if !dpm.isRetryableError(err) {
			return err
		}

		if i < maxRetries {
			waitTime := time.Duration(i+1) * 100 * time.Millisecond
			log.Printf("æ•°æ®åº“æ“ä½œå¤±è´¥ï¼Œç¬¬%dæ¬¡é‡è¯•ï¼Œç­‰å¾…%v: %v", i+1, waitTime, err)
			time.Sleep(waitTime)
		}
	}

	return fmt.Errorf("æ•°æ®åº“æ“ä½œå¤±è´¥ï¼Œå·²é‡è¯•%dæ¬¡: %w", maxRetries, lastErr)
}

// isRetryableError åˆ¤æ–­æ˜¯å¦ä¸ºå¯é‡è¯•çš„é”™è¯¯
func (dpm *DatabasePoolManager) isRetryableError(err error) bool {
	// æ£€æŸ¥å¸¸è§çš„å¯é‡è¯•é”™è¯¯
	errStr := err.Error()
	retryableErrors := []string{
		"connection refused",
		"connection reset",
		"timeout",
		"deadlock",
		"lock wait timeout",
		"server has gone away",
	}

	for _, retryableErr := range retryableErrors {
		if contains(errStr, retryableErr) {
			return true
		}
	}

	return false
}

// contains æ£€æŸ¥å­—ç¬¦ä¸²æ˜¯å¦åŒ…å«å­å­—ç¬¦ä¸²ï¼ˆå¿½ç•¥å¤§å°å†™ï¼‰
func contains(s, substr string) bool {
	return len(s) >= len(substr) && (s == substr || len(substr) == 0 ||
		(len(s) > len(substr) && s[:len(substr)] == substr) ||
		(len(s) > len(substr) && s[len(s)-len(substr):] == substr) ||
		(len(s) > len(substr) && findSubstring(s, substr)))
}

// findSubstring æŸ¥æ‰¾å­å­—ç¬¦ä¸²
func findSubstring(s, substr string) bool {
	for i := 0; i <= len(s)-len(substr); i++ {
		if s[i:i+len(substr)] == substr {
			return true
		}
	}
	return false
}

// IsHealthy æ£€æŸ¥æ•°æ®åº“æ˜¯å¦å¥åº·
func (dpm *DatabasePoolManager) IsHealthy() bool {
	dpm.mu.RLock()
	defer dpm.mu.RUnlock()
	return dpm.isHealthy
}

// Close å…³é—­æ•°æ®åº“è¿æ¥æ± ç®¡ç†å™¨
func (dpm *DatabasePoolManager) Close() {
	if dpm.cancel != nil {
		dpm.cancel()
	}
	if dpm.healthCheckTicker != nil {
		dpm.healthCheckTicker.Stop()
	}
	log.Printf("æ•°æ®åº“è¿æ¥æ± ç®¡ç†å™¨å·²å…³é—­")
}

// QueryOptimizer æŸ¥è¯¢ä¼˜åŒ–å™¨
type QueryOptimizer struct {
	slowQueryLog map[string]time.Duration
	mu           sync.RWMutex
}

// NewQueryOptimizer åˆ›å»ºæŸ¥è¯¢ä¼˜åŒ–å™¨
func NewQueryOptimizer() *QueryOptimizer {
	return &QueryOptimizer{
		slowQueryLog: make(map[string]time.Duration),
	}
}

// LogSlowQuery è®°å½•æ…¢æŸ¥è¯¢
func (qo *QueryOptimizer) LogSlowQuery(query string, duration time.Duration) {
	qo.mu.Lock()
	defer qo.mu.Unlock()

	// åªä¿ç•™æœ€æ…¢çš„æŸ¥è¯¢è®°å½•ï¼Œé¿å…å†…å­˜æ³„æ¼
	if len(qo.slowQueryLog) > 1000 {
		// æ¸…ç†ä¸€åŠçš„è®°å½•
		count := 0
		for key := range qo.slowQueryLog {
			delete(qo.slowQueryLog, key)
			count++
			if count >= 500 {
				break
			}
		}
	}

	// è®°å½•æˆ–æ›´æ–°æ…¢æŸ¥è¯¢
	if existingDuration, exists := qo.slowQueryLog[query]; !exists || duration > existingDuration {
		qo.slowQueryLog[query] = duration
	}

	log.Printf("ğŸŒ æ…¢æŸ¥è¯¢è®°å½• - è€—æ—¶: %v, SQL: %.100s...", duration, query)
}

// GetSlowQueries è·å–æ…¢æŸ¥è¯¢åˆ—è¡¨
func (qo *QueryOptimizer) GetSlowQueries() map[string]time.Duration {
	qo.mu.RLock()
	defer qo.mu.RUnlock()

	result := make(map[string]time.Duration)
	for query, duration := range qo.slowQueryLog {
		result[query] = duration
	}

	return result
}
